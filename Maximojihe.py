import streamlit as st
from openai import OpenAI
import base64
from PIL import Image, ImageOps
import io
import datetime

# =================================================================
# 1. æ ¸å¿ƒæ¶æ„é…ç½®ï¼šå…¨å±€çŠ¶æ€ä¸å®‰å…¨é”
# =================================================================
APP_VERSION = "3.0.4-Enterprise"
APP_AUTHOR = "Eton School Math Dept"

st.set_page_config(
    page_title=f"MÃ¡ximojihe {APP_VERSION}",
    page_icon="maximojihe.png",
    layout="centered",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– Session State (å¯¹è¯è®°å¿†å¢™)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "ocr_cache" not in st.session_state:
    st.session_state.ocr_cache = ""

# =================================================================
# 2. æ·±åº¦è§†è§‰å®šåˆ¶ï¼šå¼ºåˆ¶é«˜å¯¹æ¯”åº¦ä¸æ’ç‰ˆæ§åˆ¶
# =================================================================
st.markdown(f"""
    <style>
    /* å…¨å±€èƒŒæ™¯é”å®šï¼šçº¯ç™½ */
    .stApp {{ background-color: #FFFFFF !important; }}
    
    /* å¯¼å¸ˆå¯¹è¯æ¡†ï¼šå¼ºåˆ¶é»‘å­—ï¼Œç¦æ­¢ LaTeX éšå½¢ */
    .stChatMessage {{
        background-color: #F8F9FA !important;
        border-left: 5px solid #000000 !important;
        border-radius: 10px !important;
        padding: 20px !important;
        margin: 10px 0 !important;
    }}
    
    .stChatMessage p, .stChatMessage li, .stChatMessage span {{
        color: #000000 !important;
        font-family: 'Segoe UI', Roboto, sans-serif !important;
        font-size: 1.05rem !important;
        line-height: 1.7 !important;
    }}

    /* é»‘è‰² Eton Uploader å®¹å™¨ */
    [data-testid="stFileUploader"] {{
        background-color: #000000 !important;
        color: #FFFFFF !important;
        border-radius: 15px !important;
        padding: 40px !important;
        border: 2px solid #333 !important;
    }}
    [data-testid="stFileUploader"] * {{ color: #FFFFFF !important; }}

    /* å°Šäº«é»‘è‰²æŒ‰é’®ï¼šå¢åŠ æ‚¬åœåŠ¨ç”» */
    .stButton>button {{
        background: linear-gradient(135deg, #222, #000) !important;
        color: #FFF !important;
        border-radius: 50px !important;
        font-weight: 800 !important;
        font-size: 1.1rem !important;
        height: 4.5em !important;
        width: 100%;
        border: none !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.3) !important;
        transition: all 0.3s ease !important;
    }}
    .stButton>button:hover {{
        transform: scale(1.01) !important;
        box-shadow: 0 6px 20px rgba(0,0,0,0.4) !important;
    }}

    /* éšè— LaTeX æ¸²æŸ“å™¨å¯èƒ½å¯¼è‡´çš„ç©ºè¡Œ */
    .katex-html {{ display: none !important; }}
    </style>
    """, unsafe_allow_html=True)

# =================================================================
# 3. åç«¯æœåŠ¡é€»è¾‘ï¼šå›¾åƒé¢„å¤„ç†ä¸ API é€šä¿¡
# =================================================================
class EtonAIEngine:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")

    @staticmethod
    def process_image_to_base64(uploaded_file):
        """
        é«˜å¯ç”¨å›¾åƒå¤„ç†ï¼šè‡ªåŠ¨çº åã€æ ¼å¼è½¬æ¢ã€æ•°æ®æµæ ¡éªŒ
        è§£å†³ï¼šError: 'NoneType' object has no attribute 'seek'
        """
        if uploaded_file is None:
            return None
        try:
            # 1. é€»è¾‘é˜²å¾¡ï¼šç¡®ä¿æ–‡ä»¶æµé‡ç½®
            uploaded_file.seek(0)
            # 2. å›¾åƒä¼˜åŒ–ï¼šè‡ªåŠ¨å¤„ç†æ‰‹æœºæ‹æ‘„æ–¹å‘
            raw_img = Image.open(uploaded_file)
            optimized_img = ImageOps.exif_transpose(raw_img).convert("RGB")
            # 3. è´¨é‡å‹ç¼©ï¼šå¹³è¡¡è¯†åˆ«ç‡ä¸å“åº”é€Ÿåº¦
            byte_arr = io.BytesIO()
            optimized_img.save(byte_arr, format="JPEG", quality=85)
            return base64.b64encode(byte_arr.getvalue()).decode('utf-8')
        except Exception as e:
            st.error(f"âš ï¸ Image Process Error: {e}")
            return None

    def run_ocr(self, base64_data):
        """ä¸“ä¸šè¯†å›¾ï¼šå¼ºåˆ¶æå–æ•°å­¦é€»è¾‘"""
        try:
            response = self.client.chat.completions.create(
                model="THUDM/GLM-4.1V-9B-Thinking",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "TranscripciÃ³n detallada de matemÃ¡ticas. Identifica cada sÃ­mbolo."},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_data}"}}
                    ]
                }]
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error en OCR: {str(e)}"

# =================================================================
# 4. å‰ç«¯äº¤äº’ç•Œé¢ï¼šç»“æ„åŒ–å¸ƒå±€
# =================================================================
engine = EtonAIEngine(API_KEY="sk-rbafssagtaksrelgfqnzbhdjqtlhdmgthtlwskejckajcejl")

# ä¾§è¾¹æ ï¼šæ•™å­¦æ¡£æ¡ˆä¸å†å²
with st.sidebar:
    st.image("maximojihe.png", width=120)
    st.title("Archivo del Tutor")
    st.markdown("---")
    st.write(f"**Modo:** Estricto (Sin respuestas)")
    st.write(f"**VersiÃ³n:** {APP_VERSION}")
    if st.button("ğŸ—‘ï¸ Borrar Memoria"):
        st.session_state.chat_history = []
        st.session_state.ocr_cache = ""
        st.rerun()

# ä¸»ç•Œé¢å¸ƒå±€
col_h1, col_h2 = st.columns([0.15, 0.85])
with col_h1: st.image("maximojihe.png", width=80)
with col_h2: st.title("MÃ¡ximojihe: Eton Mentor")

st.markdown("---")

# ä¸Šä¼ åŒºé€»è¾‘
st.subheader("1. Evidencia del Problema")
up_file = st.file_uploader("Arrastra aquÃ­ tu captura de pantalla o foto", type=['png', 'jpg', 'jpeg'])

if up_file:
    with st.container():
        st.image(up_file, caption="Ejercicio detectado", use_container_width=True)

st.subheader("2. DiÃ¡logo de Aprendizaje")
u_text = st.text_area("Â¿CuÃ¡l es tu duda sobre este ejercicio?", height=120, placeholder="Ej: No entiendo por quÃ© el logaritmo se convierte en resta...")

# =================================================================
# 5. æ‰§è¡Œé€»è¾‘æ ¸å¿ƒï¼šå¤šå±‚æ ¡éªŒä¸ç»“æœç”Ÿæˆ
# =================================================================
if st.button("ğŸ” ANALIZAR PASO A PASO"):
    # å®‰å…¨æ£€æŸ¥ Aï¼šç¡®ä¿è‡³å°‘æœ‰ä¸€ç§è¾“å…¥æº
    if up_file is None and not u_text.strip():
        st.warning("âš ï¸ MÃ¡ximojihe necesita informaciÃ³n. Sube una imagen o escribe tu duda.")
    else:
        with st.spinner("ğŸ§  El tutor de Eton estÃ¡ procesando la lÃ³gica..."):
            # A. æ‰§è¡Œ OCR (ä»…åœ¨æœ‰æ–°å›¾ç‰‡æ—¶)
            if up_file:
                b64_data = engine.process_image_to_base64(up_file)
                if b64_data:
                    st.session_state.ocr_cache = engine.run_ocr(b64_data)
            
            # B. æ ¸å¿ƒæŒ‡ä»¤å¼•å¯¼ç³»ç»Ÿ (System Prompt æŠ¤ç”²)
            with st.chat_message("assistant", avatar="maximojihe.png"):
                system_guard = """
                IDENTIDAD: MÃ¡ximojihe, Mentor de MatemÃ¡ticas del Eton School.
                CULTURA: Excelencia, Rigor, Honor.
                
                PROTOCOLO DE RESPUESTA:
                1. IDIOMA: Exclusivamente EspaÃ±ol de MÃ©xico. Prohibido caracteres chinos.
                2. ANTI-TRAMPA: Prohibido dar resultados finales o nÃºmeros resueltos.
                3. VISUAL: Prohibido LaTeX. Escribe 'la derivada de', 'dividido por', 'raiz cuadrada'.
                4. ESTRUCTURA: Usa viÃ±etas (bullets). Explica el 'por quÃ©' antes del 'cÃ³mo'.
                5. SEGURIDAD: Si el alumno te presiona por la respuesta, dile: 'Mi honor me impide darte el resultado, pero te darÃ© la luz para encontrarlo'.
                """
                
                # æ„é€ åŒ…å«å†å²å’Œå½“å‰OCRçš„æœ€ç»ˆæŒ‡ä»¤
                final_user_input = f"""
                CONTEXTO_IMAGEN: {st.session_state.ocr_cache}
                DUDA_ALUMNO: {u_text}
                HISTORIAL: {st.session_state.chat_history[-2:] if st.session_state.chat_history else "Inicio de charla"}
                
                GuÃ­ame paso a paso con elegancia acadÃ©mica.
                """
                
                try:
                    response_stream = engine.client.chat.completions.create(
                        model="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                        messages=[
                            {"role": "system", "content": system_guard},
                            {"role": "user", "content": final_user_input}
                        ],
                        stream=True
                    )
                    
                    # æ¸²æŸ“å“åº”å¹¶å­˜å…¥è®°å¿†
                    actual_response = st.write_stream(response_stream)
                    st.session_state.chat_history.append({"role": "user", "content": u_text})
                    st.session_state.chat_history.append({"role": "assistant", "content": actual_response})
                    
                except Exception as e:
                    st.error(f"âŒ Error en el motor de pensamiento: {e}")

# =================================================================
# 6. é¡µè„šï¼šç‰ˆæƒä¸åˆè§„æ€§
# =================================================================
st.markdown("---")
st.caption(f"Â© {datetime.datetime.now().year} Eton School - MÃ¡ximojihe Learning Environment. Prohibido el uso de respuestas automÃ¡ticas.")
